package shardkv

import (
	"cs134-24f-kv/paxos"
	"cs134-24f-kv/shardmaster"
	"encoding/gob"
	"fmt"
	"log"
	"math/rand"
	"net"
	"net/rpc"
	"os"
	"sync"
	"sync/atomic"
	"syscall"
	"time"
)

const Debug = 1

func DPrintf(format string, a ...interface{}) (n int, err error) {
	if Debug > 0 {
		log.Printf(format, a...)
	}
	return
}

type Op struct {
	// Your definitions here.
	Type      string
	Key       string
	Value     string
	ClientId  int64
	SeqNum    int64
	Config    shardmaster.Config
	Shard     int
	Data      map[string]string
	ClientSeq map[int64]int64
}

type ShardKV struct {
	mu         sync.Mutex
	l          net.Listener
	me         int
	dead       int32 // for testing
	unreliable int32 // for testing
	sm         *shardmaster.Clerk
	px         *paxos.Paxos

	gid int64 // my replica group ID

	// TODO: Your definitions here.
	config      shardmaster.Config
	kvstore     map[int]map[string]string
	clientSeq   map[int64]int64
	lastApplied int
}

func (kv *ShardKV) wait(seq int) Op {
	to := 10 * time.Millisecond
	for {
		decided, value := kv.px.Status(seq)
		if decided == paxos.Decided {
			return value.(Op)
		}
		time.Sleep(to)
		if to < 10*time.Second {
			to *= 2
		}
	}
}

func (kv *ShardKV) Get(args *GetArgs, reply *GetReply) error {
	// TODO: Your code here.
	kv.mu.Lock()
	defer kv.mu.Unlock()

	shard := key2shard(args.Key)
	fmt.Printf("GID %d Server %d: Get request for key %s (shard %d, config %d)\n",
		kv.gid, kv.me, args.Key, shard, kv.config.Num)

	// First verify we should handle this shard
	if kv.config.Shards[shard] != kv.gid {
		reply.Err = ErrWrongGroup
		return nil
	}

	// Then check for duplicate requests
	if seq, ok := kv.clientSeq[args.ClientId]; ok && args.SeqNum <= seq {
		if args.SeqNum == seq {
			if kv.kvstore[shard] != nil {
				if value, exists := kv.kvstore[shard][args.Key]; exists {
					reply.Value = value
					reply.Err = OK
				} else {
					reply.Err = ErrNoKey
				}
			}
		}
		return nil
	}

	// Create operation and run Paxos
	op := Op{
		Type:     "Get",
		Key:      args.Key,
		ClientId: args.ClientId,
		SeqNum:   args.SeqNum,
	}

	// Run consensus
	seq := kv.lastApplied + 1
	kv.px.Start(seq, op)
	decided := kv.wait(seq)
	kv.apply(seq)

	// Check result after apply
	if kv.config.Shards[shard] != kv.gid {
		reply.Err = ErrWrongGroup
		return nil
	}

	if decided.Type == op.Type && decided.ClientId == op.ClientId && decided.SeqNum == op.SeqNum {
		if kv.kvstore[shard] != nil {
			if value, exists := kv.kvstore[shard][args.Key]; exists {
				reply.Value = value
				reply.Err = OK
				kv.clientSeq[args.ClientId] = args.SeqNum
				return nil
			}
			reply.Err = ErrNoKey
			kv.clientSeq[args.ClientId] = args.SeqNum
			return nil
		}
	}

	reply.Err = ErrWrongGroup
	return nil
}

// RPC handler for client Put and Append requests
func (kv *ShardKV) PutAppend(args *PutAppendArgs, reply *PutAppendReply) error {
	// TODO: Your code here.
	kv.mu.Lock()
	defer kv.mu.Unlock()

	// Check if we serve this key's shard
	shard := key2shard(args.Key)
	fmt.Printf("GID %d Server %d: %s request for key %s (shard %d, config %d)\n",
		kv.gid, kv.me, args.Op, args.Key, shard, kv.config.Num)
	if kv.config.Shards[shard] != kv.gid {
		reply.Err = ErrWrongGroup
		return nil
	}

	// Create operation and start Paxos agreement
	op := Op{
		Type:     args.Op,
		Key:      args.Key,
		Value:    args.Value,
		ClientId: args.ClientId,
		SeqNum:   args.SeqNum,
	}

	// Run Paxos consensus
	seq := kv.lastApplied + 1
	kv.px.Start(seq, op)
	decided := kv.wait(seq)
	kv.apply(seq)

	// Check if our operation was decided
	if decided.Type == op.Type && decided.ClientId == op.ClientId && decided.SeqNum == op.SeqNum {
		reply.Err = OK
		return nil
	}

	reply.Err = ErrWrongGroup
	return nil
}

func (kv *ShardKV) apply(seq int) {
	for i := kv.lastApplied + 1; i <= seq; i++ {
		decided, value := kv.px.Status(i)
		if decided == paxos.Decided {
			op := value.(Op)
			switch op.Type {
			case "Transfer":
				fmt.Printf("GID %d Server %d: Applying transfer of shard %d with %d keys\n",
					kv.gid, kv.me, op.Shard, len(op.Data))
				if kv.kvstore[op.Shard] == nil {
					kv.kvstore[op.Shard] = make(map[string]string)
				}
				// Copy received data
				for k, v := range op.Data {
					kv.kvstore[op.Shard][k] = v
				}
				// Update client sequence numbers
				for cid, seq := range op.ClientSeq {
					if seq > kv.clientSeq[cid] {
						kv.clientSeq[cid] = seq
					}
				}

			case "Reconfigure":
				if op.Config.Num == kv.config.Num+1 {
					fmt.Printf("GID %d Server %d: Applying config change from %d to %d. Old shards: %v, New shards: %v\n",
						kv.gid, kv.me, kv.config.Num, op.Config.Num, kv.config.Shards, op.Config.Shards)

					// Keep old data around temporarily
					oldConfig := kv.config
					newConfig := op.Config
					oldStore := kv.kvstore
					newStore := make(map[int]map[string]string)

					// Copy data for shards we'll own in new config
					for shard := 0; shard < shardmaster.NShards; shard++ {
						if newConfig.Shards[shard] == kv.gid {
							newStore[shard] = make(map[string]string)
							// Copy existing data if we have it
							if oldStore[shard] != nil {
								for k, v := range oldStore[shard] {
									newStore[shard][k] = v
								}
							}
						} else if oldConfig.Shards[shard] == kv.gid {
							// Keep old data around temporarily
							newStore[shard] = oldStore[shard]
						}
					}

					kv.kvstore = newStore
					kv.config = newConfig
					fmt.Printf("GID %d Server %d: Completed config change to %d\n",
						kv.gid, kv.me, newConfig.Num)
				}

			default: // Put/Append/Get
				shard := key2shard(op.Key)
				// Allow operations on shards we own in current config
				// OR shards we owned in previous config but haven't transferred yet
				if kv.config.Shards[shard] == kv.gid {
					fmt.Printf("GID %d Server %d: Applying op %s for key %s (shard %d, owned=true)\n",
						kv.gid, kv.me, op.Type, op.Key, shard)
					if kv.kvstore[shard] == nil {
						kv.kvstore[shard] = make(map[string]string)
					}
					if op.SeqNum > kv.clientSeq[op.ClientId] {
						switch op.Type {
						case "Put":
							kv.kvstore[shard][op.Key] = op.Value
						case "Append":
							oldVal := kv.kvstore[shard][op.Key]
							kv.kvstore[shard][op.Key] = oldVal + op.Value
						}
						kv.clientSeq[op.ClientId] = op.SeqNum
					}
				}
			}
		}
	}
	kv.lastApplied = seq
	kv.px.Done(seq)
}

func (kv *ShardKV) Transfer(args *TransferArgs, reply *TransferReply) error {
	kv.mu.Lock()
	defer kv.mu.Unlock()

	// Allow transfers if we're at args.ConfigNum OR args.ConfigNum + 1
	if kv.config.Num != args.ConfigNum && kv.config.Num != args.ConfigNum+1 {
		reply.Err = ErrWrongGroup
		return nil
	}

	reply.Err = OK
	reply.KV = make(map[string]string)
	reply.ClientSeq = make(map[int64]int64)

	// Copy shard data
	if data := kv.kvstore[args.Shard]; data != nil {
		for k, v := range data {
			reply.KV[k] = v
		}
	}

	// Copy client sequence numbers
	for cid, seq := range kv.clientSeq {
		reply.ClientSeq[cid] = seq
	}

	return nil
}

// Ask the shardmaster if there's a new configuration;
// if so, re-configure.
func (kv *ShardKV) tick() {
	kv.mu.Lock()
	defer kv.mu.Unlock()

	newConfig := kv.sm.Query(-1)
	if newConfig.Num > kv.config.Num {
		// Process configurations one at a time
		nextConfig := kv.sm.Query(kv.config.Num + 1)

		// Track which shards we need to fetch
		needShards := make(map[int]bool)
		for shard := 0; shard < shardmaster.NShards; shard++ {
			if nextConfig.Shards[shard] == kv.gid && kv.config.Shards[shard] != kv.gid {
				needShards[shard] = true
			}
		}

		// Try to get all needed shards
		if len(needShards) > 0 {
			for shard := range needShards {
				oldGid := kv.config.Shards[shard]
				if oldGid != 0 {
					if servers, ok := kv.config.Groups[oldGid]; ok {
						for _, srv := range servers {
							args := &TransferArgs{
								Shard:     shard,
								ConfigNum: kv.config.Num,
							}
							var reply TransferReply
							ok := call(srv, "ShardKV.Transfer", args, &reply)
							if ok && reply.Err == OK {
								op := Op{
									Type:      "Transfer",
									Shard:     shard,
									Data:      reply.KV,
									ClientSeq: reply.ClientSeq,
								}
								seq := kv.lastApplied + 1
								kv.px.Start(seq, op)
								kv.wait(seq)
								kv.apply(seq)
								delete(needShards, shard)
								break
							}
						}
					}
				} else {
					delete(needShards, shard)
				}
			}
		}

		// Only proceed if we have all needed shards
		if len(needShards) == 0 {
			op := Op{
				Type:   "Reconfigure",
				Config: nextConfig,
			}
			seq := kv.lastApplied + 1
			kv.px.Start(seq, op)
			kv.wait(seq)
			kv.apply(seq)
		}
	}
}

// tell the server to shut itself down.
// please don't change these two functions.
func (kv *ShardKV) kill() {
	atomic.StoreInt32(&kv.dead, 1)
	kv.l.Close()
	kv.px.Kill()
}

// call this to find out if the server is dead.
func (kv *ShardKV) isdead() bool {
	return atomic.LoadInt32(&kv.dead) != 0
}

// please do not change these two functions.
func (kv *ShardKV) Setunreliable(what bool) {
	if what {
		atomic.StoreInt32(&kv.unreliable, 1)
	} else {
		atomic.StoreInt32(&kv.unreliable, 0)
	}
}

func (kv *ShardKV) isunreliable() bool {
	return atomic.LoadInt32(&kv.unreliable) != 0
}

// Start a shardkv server.
// gid is the ID of the server's replica group.
// shardmasters[] contains the ports of the
//
//	servers that implement the shardmaster.
//
// servers[] contains the ports of the servers
//
//	in this replica group.
//
// Me is the index of this server in servers[].
func StartServer(gid int64, shardmasters []string,
	servers []string, me int) *ShardKV {
	gob.Register(Op{})

	kv := new(ShardKV)
	kv.me = me
	kv.gid = gid
	kv.sm = shardmaster.MakeClerk(shardmasters)

	// TODO: Your initialization code here.
	// Don't call Join().
	kv.config = shardmaster.Config{Num: 0, Shards: [10]int64{}, Groups: map[int64][]string{}}
	kv.kvstore = make(map[int]map[string]string)
	kv.clientSeq = make(map[int64]int64)

	rpcs := rpc.NewServer()
	rpcs.Register(kv)

	kv.px = paxos.Make(servers, me, rpcs)

	os.Remove(servers[me])
	l, e := net.Listen("unix", servers[me])
	if e != nil {
		log.Fatal("listen error: ", e)
	}
	kv.l = l

	// please do not change any of the following code,
	// or do anything to subvert it.

	go func() {
		for kv.isdead() == false {
			conn, err := kv.l.Accept()
			if err == nil && kv.isdead() == false {
				if kv.isunreliable() && (rand.Int63()%1000) < 100 {
					// discard the request.
					conn.Close()
				} else if kv.isunreliable() && (rand.Int63()%1000) < 200 {
					// process the request but force discard of reply.
					c1 := conn.(*net.UnixConn)
					f, _ := c1.File()
					err := syscall.Shutdown(int(f.Fd()), syscall.SHUT_WR)
					if err != nil {
						fmt.Printf("shutdown: %v\n", err)
					}
					go rpcs.ServeConn(conn)
				} else {
					go rpcs.ServeConn(conn)
				}
			} else if err == nil {
				conn.Close()
			}
			if err != nil && kv.isdead() == false {
				fmt.Printf("ShardKV(%v) accept: %v\n", me, err.Error())
				kv.kill()
			}
		}
	}()

	go func() {
		for kv.isdead() == false {
			kv.tick()
			time.Sleep(250 * time.Millisecond)
		}
	}()

	return kv
}
